name: Bootstrap: AI Market Agent
on:
  workflow_dispatch:
permissions:
  contents: write

jobs:
  bootstrap:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Create project files
        shell: bash
        run: |
          set -e
          mkdir -p .github/workflows src/sources src/notify data

          # Root files
          cat > README.md <<'EOF'
# AI Market Agent (Nightly, 10 PM IST)
This repo fetches Indian markets news from Google News RSS (Moneycontrol, ET Markets, Mint, Business Standard, NSE), clusters similar stories, maps them to companies, scores sentiment, and emails a nightly report.
EOF

          cat > requirements.txt <<'EOF'
feedparser
beautifulsoup4
requests
pandas
numpy
rapidfuzz
vaderSentiment
python-dotenv
EOF

          cat > .env.example <<'EOF'
SMTP_USER=you@gmail.com
SMTP_PASS=your_16_char_app_password
EMAIL_TO=you@gmail.com
TELEGRAM_BOT_TOKEN=
TELEGRAM_CHAT_ID=
EOF

          cat > .github/workflows/daily.yml <<'EOF'
name: nightly-report
on:
  schedule:
    - cron: "30 16 * * *"
  workflow_dispatch: {}
jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: pip install -r requirements.txt
      - env:
          SMTP_USER: ${{ secrets.SMTP_USER }}
          SMTP_PASS: ${{ secrets.SMTP_PASS }}
          EMAIL_TO: ${{ secrets.EMAIL_TO }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: python -m src.job_daily
EOF

          # src/
          printf "" > src/__init__.py
          cat > src/config.py <<'EOF'
from zoneinfo import ZoneInfo
import os
IST = ZoneInfo("Asia/Kolkata")
NEWS_DOMAINS = [
    "moneycontrol.com",
    "economictimes.indiatimes.com",
    "livemint.com",
    "business-standard.com",
    "nseindia.com",
]
LOOKBACK_HOURS = int(os.getenv("LOOKBACK_HOURS", "36"))
SMTP_HOST = os.getenv("SMTP_HOST", "smtp.gmail.com")
SMTP_PORT = int(os.getenv("SMTP_PORT", "587"))
SMTP_USER = os.getenv("SMTP_USER", "")
SMTP_PASS = os.getenv("SMTP_PASS", "")
EMAIL_TO  = os.getenv("EMAIL_TO", "")
ENABLE_TELEGRAM = os.getenv("ENABLE_TELEGRAM", "false").lower() in {"1","true","yes"}
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "")
DB_PATH = os.getenv("DB_PATH", "ai_agent.db")
WEIGHT_BY_DOMAIN = {
    "nseindia.com": 1.5,
    "business-standard.com": 1.2,
    "livemint.com": 1.2,
    "economictimes.indiatimes.com": 1.0,
    "moneycontrol.com": 1.0,
}
DEFAULT_DOMAIN_WEIGHT = 1.0
EOF

          cat > src/db.py <<'EOF'
import sqlite3
from typing import Iterable, Dict, Any
def get_conn(db_path: str):
    conn = sqlite3.connect(db_path)
    conn.execute("PRAGMA journal_mode=WAL;")
    conn.execute("PRAGMA synchronous=NORMAL;")
    return conn
def init_db(conn: sqlite3.Connection):
    conn.executescript('''
        CREATE TABLE IF NOT EXISTS articles (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            source TEXT,
            url TEXT UNIQUE,
            title TEXT,
            published_at TEXT,
            summary TEXT,
            raw_text TEXT
        );
    ''')
    conn.commit()
def insert_articles(conn, rows: Iterable[Dict[str, Any]]):
    cur = conn.cursor()
    for r in rows:
        try:
            cur.execute(
                "INSERT OR IGNORE INTO articles (source, url, title, published_at, summary, raw_text) VALUES (?, ?, ?, ?, ?, ?)",
                (r["source"], r["url"], r["title"], r["published_at"], r.get("summary",""), r.get("raw_text","")),
            )
        except:
            pass
    conn.commit()
def fetch_recent_articles(conn, since_iso: str):
    cur = conn.cursor()
    cur.execute("SELECT id, source, url, title, published_at, summary, raw_text FROM articles WHERE published_at >= ? ORDER BY published_at DESC", (since_iso,))
    cols = [d[0] for d in cur.description]
    return [dict(zip(cols, row)) for row in cur.fetchall()]
EOF

          cat > src/normalize.py <<'EOF'
import re
from typing import Optional
def clean_text(s: Optional[str]) -> str:
    if not s: return ""
    s = re.sub(r'<[^>]+>', ' ', s)
    s = s.replace('\xa0',' ')
    s = re.sub(r'\s+',' ', s).strip()
    return s[:4000]
EOF

          cat > src/dedupe.py <<'EOF'
from typing import List, Dict, Any
from rapidfuzz import fuzz
def cluster_articles(articles: List[Dict[str, Any]], title_threshold: int = 88) -> List[List[Dict[str, Any]]]:
    clusters: List[List[Dict[str, Any]]] = []
    used = [False] * len(articles)
    for i, a in enumerate(articles):
        if used[i]: continue
        group = [a]; used[i] = True
        for j in range(i+1, len(articles)):
            if used[j]: continue
            b = articles[j]
            tscore = fuzz.token_set_ratio(a.get("title",""), b.get("title",""))
            if tscore >= title_threshold:
                group.append(b); used[j] = True
        clusters.append(group)
    return clusters
EOF

          cat > src/entities.py <<'EOF'
import csv, re
from typing import List, Dict
def load_companies(csv_path: str):
    companies = []
    with open(csv_path, newline='', encoding='utf-8') as f:
        r = csv.DictReader(f)
        for row in r:
            aliases = [a.strip() for a in (row.get("ALIASES") or "").split(";") if a.strip()]
            companies.append({"symbol": row["SYMBOL"].strip(),"name": row["COMPANY_NAME"].strip(),"aliases": aliases})
    return companies
def find_mentions(text: str, companies: List[Dict[str, str]]):
    text_low = text.lower(); hits = []
    for c in companies:
        names = [c["name"]] + c["aliases"]
        for nm in names:
            nm_low = nm.lower()
            if re.search(rf'\b{re.escape(nm_low)}\b', text_low):
                hits.append(c["symbol"]); break
    return list(sorted(set(hits)))
EOF

          cat > src/score.py <<'EOF'
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from collections import defaultdict
from typing import List, Dict, Any, Tuple
def compute_cluster_sentiment(cluster: List[Dict[str, Any]], weight_by_domain: Dict[str, float], default_weight: float):
    analyzer = SentimentIntensityAnalyzer(); s=w=0.0
    for a in cluster:
        txt = (a.get("title","") + " " + a.get("summary","")).strip()
        vs = analyzer.polarity_scores(txt)
        wd = weight_by_domain.get(a["source"], default_weight)
        s += vs["compound"] * wd; w += wd
    return (s / w) if w else 0.0
def aggregate_by_symbol(clusters_with_entities: List[Tuple[List[Dict[str, Any]], List[str]]], weight_by_domain: Dict[str, float], default_weight: float):
    pos, neg, reasons = defaultdict(float), defaultdict(float), defaultdict(list)
    for cluster, syms in clusters_with_entities:
        if not syms: continue
        sent = compute_cluster_sentiment(cluster, weight_by_domain, default_weight)
        titles = [a["title"] for a in cluster[:2]]; reason = "; ".join(titles)[:220]
        for s in syms:
            (pos if sent>=0 else neg)[s] += abs(sent)
            reasons[s].append(reason)
    return pos, neg, reasons
def top_n(d: Dict[str, float], n=5):
    return sorted(d.items(), key=lambda x: x[1], reverse=True)[:n]
EOF

          cat > src/report.py <<'EOF'
from typing import Dict, List
def build_report_html(date_str: str, top_pos: List, top_neg: List, reasons: Dict[str, List[str]]):
    def block(title, items):
        html = f"<h2>{title}</h2><ol>"
        for sym, score in items:
            bullets = "".join(f"<li>{r}</li>" for r in reasons.get(sym, [])[:3])
            html += f"<li><strong>{sym}</strong> — {score:.2f}<ul>{bullets}</ul></li>"
        html += "</ol>"; return html
    return f"""
    <html><body>
    <h1>Daily Market Impact — {date_str}</h1>
    {block("Top 5 Positive", top_pos)}
    {block("Top 5 Negative", top_neg)}
    </body></html>
    """
def build_report_text(date_str: str, top_pos: List, top_neg: List, reasons: Dict[str, List[str]]):
    def block(title, items):
        out=[title]
        for sym, score in items:
            Rs = reasons.get(sym, [])[:3]
            out.append(f"- {sym} — {score:.2f}")
            for r in Rs: out.append(f"  • {r}")
        return "\n".join(out)
    txt = f"Daily Market Impact — {date_str}\n\n"
    txt += block("Top 5 Positive", top_pos) + "\n\n"
    txt += block("Top 5 Negative", top_neg) + "\n"
    return txt
EOF

          cat > src/job_daily.py <<'EOF'
from datetime import datetime, timedelta
from .config import (
    IST, LOOKBACK_HOURS, NEWS_DOMAINS, 
    SMTP_HOST, SMTP_PORT, SMTP_USER, SMTP_PASS, EMAIL_TO,
    ENABLE_TELEGRAM, TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID,
    DB_PATH, WEIGHT_BY_DOMAIN, DEFAULT_DOMAIN_WEIGHT
)
from . import db
from .sources.google_news import fetch_for_domain
from .normalize import clean_text
from .dedupe import cluster_articles
from .entities import load_companies, find_mentions
from .score import aggregate_by_symbol, top_n
from .report import build_report_html, build_report_text
from .notify.emailer import send_email
from .notify.telegram import send_telegram
def main():
    now_ist = datetime.now(IST)
    since_ist = now_ist - timedelta(hours=LOOKBACK_HOURS)
    conn = db.get_conn(DB_PATH); db.init_db(conn)
    all_articles = []
    for dom in NEWS_DOMAINS:
        try:
            for a in fetch_for_domain(dom):
                a.summary = clean_text(a.summary)
                all_articles.append({
                    "source": a.source, "url": a.url, "title": a.title,
                    "published_at": a.published_at.isoformat(timespec="seconds"),
                    "summary": a.summary, "raw_text": a.raw_text or ""
                })
        except Exception: continue
    db.insert_articles(conn, all_articles)
    recent = db.fetch_recent_articles(conn, since_ist.isoformat(timespec="seconds"))
    if not recent: print("No recent articles found."); return
    clusters = cluster_articles(recent, title_threshold=88)
    companies = load_companies("data/companies_master.csv")
    clusters_with_entities=[]
    for cl in clusters:
        bag = " ".join([(c.get("title","") + " " + c.get("summary","")) for c in cl])
        syms = find_mentions(bag, companies)
        clusters_with_entities.append((cl, syms))
    pos, neg, reasons = aggregate_by_symbol(clusters_with_entities, WEIGHT_BY_DOMAIN, DEFAULT_DOMAIN_WEIGHT)
    top_pos = top_n(pos, 5); top_neg = top_n(neg, 5)
    date_str = now_ist.strftime("%Y-%m-%d %H:%M IST")
    html = build_report_html(date_str, top_pos, top_neg, reasons)
    txt  = build_report_text(date_str, top_pos, top_neg, reasons)
    subject = f"Daily Market Impact — {date_str}"
    if SMTP_USER and SMTP_PASS and EMAIL_TO:
        send_email(SMTP_HOST, SMTP_PORT, SMTP_USER, SMTP_PASS, EMAIL_TO, subject, html, txt)
        print("Email sent.")
    else:
        print("Email not configured (set SMTP_USER, SMTP_PASS, EMAIL_TO).")
    if ENABLE_TELEGRAM and TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID:
        send_telegram(TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, txt[:4000])
        print("Telegram sent.")
if __name__ == "__main__":
    main()
EOF

          # sources/
          printf "" > src/sources/__init__.py
          cat > src/sources/base.py <<'EOF'
from dataclasses import dataclass
from datetime import datetime
from typing import Optional
@dataclass
class Article:
    source: str
    url: str
    title: str
    published_at: datetime
    summary: Optional[str] = None
    raw_text: Optional[str] = None
EOF

          cat > src/sources/google_news.py <<'EOF'
from datetime import datetime
from typing import List
from urllib.parse import quote_plus
import feedparser
from .base import Article
def _feed_url_for_domain(domain: str) -> str:
    query = f"site:{domain}"
    return f"https://news.google.com/rss/search?q={quote_plus(query)}+when:2d&hl=en-IN&gl=IN&ceid=IN:en"
def fetch_for_domain(domain: str) -> List[Article]:
    feed = feedparser.parse(_feed_url_for_domain(domain))
    out: List[Article] = []
    for e in feed.entries:
        if hasattr(e, 'published_parsed') and e.published_parsed:
            dt = datetime(*e.published_parsed[:6])
        elif hasattr(e, 'updated_parsed') and e.updated_parsed:
            dt = datetime(*e.updated_parsed[:6])
        else:
            dt = datetime.utcnow()
        title = getattr(e, "title", "(no title)")
        link = getattr(e, "link", "")
        summary = getattr(e, "summary", "") or ""
        out.append(Article(source=domain, url=link, title=title.strip(), published_at=dt, summary=summary, raw_text=None))
    return out
EOF

          # notify/
          printf "" > src/notify/__init__.py
          cat > src/notify/emailer.py <<'EOF'
import smtplib, ssl
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
def send_email(smtp_host, smtp_port, smtp_user, smtp_pass, to_addr, subject, html_body, text_body):
    msg = MIMEMultipart('alternative')
    msg['Subject'] = subject; msg['From'] = smtp_user; msg['To'] = to_addr
    msg.attach(MIMEText(text_body, 'plain', 'utf-8'))
    msg.attach(MIMEText(html_body, 'html', 'utf-8'))
    ctx = ssl.create_default_context()
    with smtplib.SMTP(smtp_host, smtp_port) as server:
        server.starttls(context=ctx); server.login(smtp_user, smtp_pass)
        server.sendmail(smtp_user, [to_addr], msg.as_string())
EOF

          cat > src/notify/telegram.py <<'EOF'
import requests
def send_telegram(bot_token: str, chat_id: str, text: str):
    if not bot_token or not chat_id: return
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    data = {"chat_id": chat_id, "text": text}
    try: requests.post(url, data=data, timeout=15)
    except Exception: pass
EOF

          # data/
          cat > data/companies_master.csv <<'EOF'
SYMBOL,COMPANY_NAME,ALIASES
RELIANCE,Reliance Industries,"Reliance;RIL;Jio"
TCS,Tata Consultancy Services,"TCS;Tata Consultancy"
INFY,Infosys,"Infosys Ltd;Infosys Limited;Infy"
HDFCBANK,HDFC Bank,"HDFC Bank Ltd;HDFC;HDFCBank"
ICICIBANK,ICICI Bank,"ICICI;ICICI Bank Ltd"
SBIN,State Bank of India,"SBI;State Bank"
HINDUNILVR,Hindustan Unilever,"HUL;Hindustan Unilever Ltd"
ITC,ITC,"ITC Ltd"
LT,Larsen & Toubro,"L&T;Larsen and Toubro"
BHARTIARTL,Bharti Airtel,"Airtel;Bharti"
MARUTI,Maruti Suzuki,"Maruti;Maruti Suzuki India"
HCLTECH,HCL Technologies,"HCL;HCL Tech"
WIPRO,Wipro,"Wipro Ltd"
ULTRACEMCO,UltraTech Cement,"Ultratech;UltraTech"
SUNPHARMA,Sun Pharmaceutical,"Sun Pharma"
TITAN,Titan Company,"Titan"
AXISBANK,Axis Bank,"Axis"
KOTAKBANK,Kotak Mahindra Bank,"Kotak;Kotak Bank"
M&M,Mahindra & Mahindra,"Mahindra;M&M Ltd"
BAJFINANCE,Bajaj Finance,"Bajaj Fin;Bajaj Finance Ltd"
EOF

      - name: Commit and push files
        shell: bash
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "Bootstrap project files" || echo "Nothing to commit"
          git push
